---
title: "che"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{che}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Working example of using Convex Hull Ensembles and range bagging with the `che` package
## Matt Hill 2019

```{r setup}
library(che)
library (raster)
library (maptools)
library (rgeos)

# simple world outline from maptools package
data("wrld_simpl")
```

## this data is the in the `che` package - will implement neater soon....
```{r}
load("../data/insect_dist.Rdata")
```

## Bioclim data
```{r}
bioclimall <- raster::getData('worldclim', var='bio', res=2.5)
```


# Background creation

## Native range for this species is South Africa
```{r}
e <- extent (10, 40, -35, -15)
SAfrica <- crop (bioclimall, e)
#convert to a stack
SAfrica <- stack(unstack(SAfrica))
```

## Species data

### Halotydeus destructor
```{r fig.width=5, fig.height=5}
dist <- insect_dist[insect_dist$Species =="h_destructor" & insect_dist$Range == "Native",]

sp_df <- cbind(as.data.frame(dist[,c("Longitude", "Latitude")]),raster::extract(SAfrica, as.data.frame(dist[,c("Longitude", "Latitude")])))
plot (SAfrica[[1]])
points(as.data.frame(dist[,c("Longitude", "Latitude")]), pch=20)
```

## Biomes

The biomes are available as a shapefile from WWF
```{r}

if (!file.exists("official/wwf_terr_ecos.shp")){
  temp <- tempfile()
  download.file("https://c402277.ssl.cf1.rackcdn.com/publications/15/files/original/official_teow.zip",temp)
  unzip(temp)
  unlink(temp)
}
terres <- readShapePoly("official/wwf_terr_ecos.shp")
```


## Create a raster using biomes and native range points

Using the `che::background_builder` function to set up sampling environment

```{r fig.width= 5, fig.height=5}
clim <- cbind(as.data.frame(dist[,c("Longitude", "Latitude")]),raster::extract(SAfrica, as.data.frame(dist[,c("Longitude", "Latitude")])))

nat_ras <- background_builder(clim, terres, wrld_simpl, ref_rast = bioclimall[[1]])

plot (nat_ras)
```

This next bit is a whole lot of data formatting that can probably be trimmed down somewhat.
```{r}

## you'll need: bioclimall, nat_ras, SAfrica, clim

## create a stack of predictors masked to training region
predict.nat <- crop (bioclimall, nat_ras)
predict.nat <- mask (predict.nat, nat_ras)

## rasters where to predict to (these are the SAfrica ones from before)
predict.to <- SAfrica

## Rasterize the points to the same
natraster <- rasterize (clim[,1:2], predict.nat)
natraster <- reclassify (natraster, c(0, Inf, 1))

bioclimPres <- mask (predict.nat, natraster)
natptsall <- as.data.frame(rasterToPoints(bioclimPres, xy=TRUE))
natptsall <- natptsall[complete.cases(natptsall),]


## keep all the presence points in the background (ignore P/A at this point)
backall <- as.data.frame(rasterToPoints(predict.nat, xy=TRUE))
backall <- backall[complete.cases(backall),]

if (length(backall[,1]) > 50000){
  backall <- dplyr::sample_n(backall, 50000, replace=FALSE)
}


pbg.env <- rbind(natptsall, backall)
pbg.env <- pbg.env[,3:ncol(pbg.env)]
pbg.which <- c(rep(1, nrow(natptsall)), rep(0, nrow(backall)))
spp.data <- data.frame(cbind(pbg.which, pbg.env))
PA <- pbg.which
PA2 <- as.factor (PA)

## background weighting
cell_size<-area(nat_ras, na.rm=TRUE, weights=FALSE)
cell_size<-cell_size[!is.na(cell_size)]
raster_area<-length(cell_size)*median(cell_size)
back.area <- raster_area
w <- rep(1.e-6, nrow(spp.data))
w[spp.data$pbg.which ==0] <- back.area / sum(spp.data$pbg.which == 0)
```

## Parallel processing of GAMs
```{r}

varsStack <- stack()
convStack <- stack()
AUC.result <- list()


spp <- "h_destuctor"

parallel = TRUE

if (parallel==TRUE){

require(parallel)

n.cores <- detectCores() - 1
cl <- makeCluster(n.cores, type="FORK", methods=F)
clusterExport(cl=cl, varlist=c('predict.to', 'convStack', 'PA', 'PA2', 'w', 'natptsall', 'pbg.which', 'backall', 'AUC.result'))
clusterEvalQ(cl, {
  require(methods)
  require(AUC)
  require(dismo)
  require(mgcv)})

# Run models on the cluster (cl), for variables (j) using the runGams function...
test <- parLapply(cl, 12:19, runCHE)
stopCluster(cl)
} else{

  for (k in 12:19){
    runCHE(k)
    ## add list
}

}
```
## Reconcile outputs

```{r}


## just reset these all first
AUC.result <- list()
convStack <- stack()
varStack <- stack ()

for (i in 1:8){
  convStack <- stack(convStack, test[[i]][[1]])
  varsStack <- stack(varsStack, test[[i]][[2]])

  temp.AUC <- unlist(test[[i]][[3]])
  AUC.result[[i]] <- temp.AUC

}


AUC.result <- unlist(AUC.result)

quantile_thresh <- (quantile (AUC.result, 0.25))
keep_AUC <- AUC.result[AUC.result > quantile_thresh]
keep_AUC <- tibble::rownames_to_column(as.data.frame(keep_AUC))


q_CHE <- che::sum.stack(convStack,keep_AUC[,1])

plot (q_CHE)
points(dist[,c("Longitude", "Latitude")], pch=20)

```

